{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================\n",
    "# Core Libraries\n",
    "# =============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# BERT Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb85ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "N_SPLITS = 5\n",
    "\n",
    "PRIMARY_WEIGHT = 0.3\n",
    "SECONDARY_WEIGHT = 0.4\n",
    "SEVERITY_WEIGHT = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0034dc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999, 5)\n",
      "(499, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>complaint_text</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>secondary_category</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1634299</td>\n",
       "      <td>Back into XXXX of 2010 during this mortgage cr...</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5505088</td>\n",
       "      <td>I checked my credit report and I am upset on w...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10979675</td>\n",
       "      <td>I am writing to dispute the accuracy of the in...</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "      <td>Problem with a company's investigation into an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7520351</td>\n",
       "      <td>A transaction from XXXX XXXX XXXX submitted a ...</td>\n",
       "      <td>Checking or savings account</td>\n",
       "      <td>Managing an account</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5847870</td>\n",
       "      <td>I was recently alerted to an account in collec...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complaint_id                                     complaint_text  \\\n",
       "0       1634299  Back into XXXX of 2010 during this mortgage cr...   \n",
       "1       5505088  I checked my credit report and I am upset on w...   \n",
       "2      10979675  I am writing to dispute the accuracy of the in...   \n",
       "3       7520351  A transaction from XXXX XXXX XXXX submitted a ...   \n",
       "4       5847870  I was recently alerted to an account in collec...   \n",
       "\n",
       "                                    primary_category  \\\n",
       "0                                           Mortgage   \n",
       "1  Credit reporting, credit repair services, or o...   \n",
       "2  Credit reporting or other personal consumer re...   \n",
       "3                        Checking or savings account   \n",
       "4                                    Debt collection   \n",
       "\n",
       "                                  secondary_category  severity  \n",
       "0           Loan modification,collection,foreclosure         2  \n",
       "1  Problem with a credit reporting company's inve...         1  \n",
       "2  Problem with a company's investigation into an...         1  \n",
       "3                                Managing an account         1  \n",
       "4                  Attempts to collect debt not owed         5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train_complaints.csv\")\n",
    "test_df = pd.read_csv(\"test_complaints.csv\")\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c73b5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)\n",
    "    text = re.sub(r\"\\S+@\\S+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "train_df[\"clean_text\"] = train_df[\"complaint_text\"].apply(clean_text)\n",
    "test_df[\"clean_text\"] = test_df[\"complaint_text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccf22d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_le = LabelEncoder()\n",
    "secondary_le = LabelEncoder()\n",
    "\n",
    "train_df[\"primary_label\"] = primary_le.fit_transform(train_df[\"primary_category\"])\n",
    "train_df[\"secondary_label\"] = secondary_le.fit_transform(train_df[\"secondary_category\"])\n",
    "\n",
    "severity = train_df[\"severity\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aab62532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TF-IDF...\n",
      "TF-IDF shape: (2999, 150000)\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    max_features=100000,\n",
    "    ngram_range=(1,2),\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3,5),\n",
    "    max_features=50000\n",
    ")\n",
    "\n",
    "print(\"Fitting TF-IDF...\")\n",
    "\n",
    "word_train = word_vectorizer.fit_transform(train_df[\"clean_text\"])\n",
    "word_test = word_vectorizer.transform(test_df[\"clean_text\"])\n",
    "\n",
    "char_train = char_vectorizer.fit_transform(train_df[\"clean_text\"])\n",
    "char_test = char_vectorizer.transform(test_df[\"clean_text\"])\n",
    "\n",
    "tfidf_train = hstack([word_train, char_train])\n",
    "tfidf_test = hstack([word_test, char_test])\n",
    "\n",
    "print(\"TF-IDF shape:\", tfidf_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af5c2c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MiniLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 425.28it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "100%|██████████| 47/47 [00:46<00:00,  1.00it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT shape: (2999, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading MiniLM...\")\n",
    "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def generate_embeddings(texts, batch_size=64):\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        emb = bert_model.encode(batch, show_progress_bar=False)\n",
    "        embeddings.append(emb)\n",
    "        \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "\n",
    "bert_train = generate_embeddings(train_df[\"clean_text\"].tolist())\n",
    "bert_test = generate_embeddings(test_df[\"clean_text\"].tolist())\n",
    "\n",
    "print(\"BERT shape:\", bert_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d0b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Feature Shape: (2999, 150384)\n"
     ]
    }
   ],
   "source": [
    "bert_train_sparse = csr_matrix(bert_train)\n",
    "bert_test_sparse = csr_matrix(bert_test)\n",
    "\n",
    "X_train = hstack([tfidf_train, 1.3 * bert_train_sparse])\n",
    "X_test = hstack([tfidf_test, 1.3 * bert_test_sparse])\n",
    "\n",
    "print(\"Final Feature Shape:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee617737",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ece1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_preds = np.zeros(len(train_df))\n",
    "secondary_preds = np.zeros(len(train_df))\n",
    "severity_preds = np.zeros(len(train_df))\n",
    "\n",
    "primary_test_preds = np.zeros((len(test_df), N_SPLITS))\n",
    "num_classes = len(secondary_le.classes_)\n",
    "secondary_test_preds = np.zeros((len(test_df), num_classes, N_SPLITS))\n",
    "severity_test_preds = np.zeros((len(test_df), N_SPLITS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e15627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OM NARAYANA MOHANTY\\Desktop\\Neural_craft\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, train_df[\"secondary_label\"])):\n",
    "\n",
    "    print(f\"\\n===== Fold {fold+1} =====\")\n",
    "\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "\n",
    "    y_primary_tr = train_df.loc[train_idx, \"primary_label\"]\n",
    "    y_secondary_tr = train_df.loc[train_idx, \"secondary_label\"]\n",
    "    y_severity_tr = severity[train_idx]\n",
    "\n",
    "    # ---------------- PRIMARY ----------------\n",
    "    primary_model = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    primary_model.fit(X_tr, y_primary_tr)\n",
    "\n",
    "    primary_preds[val_idx] = primary_model.predict(X_val)\n",
    "    primary_test_preds[:, fold] = primary_model.predict(X_test)\n",
    "\n",
    "    # ---------------- SECONDARY ----------------\n",
    "    secondary_model = lgb.LGBMClassifier(\n",
    "        objective=\"multiclass\",\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.04,\n",
    "        num_leaves=48,\n",
    "        max_depth=-1,\n",
    "        min_child_samples=20,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=SEED,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    secondary_model.fit(X_tr, y_secondary_tr)\n",
    "\n",
    "    secondary_preds[val_idx] = secondary_model.predict(X_val)\n",
    "    secondary_test_preds[:, :, fold] = secondary_model.predict_proba(X_test)\n",
    "\n",
    "    # ---------------- SEVERITY ----------------\n",
    "    severity_model = lgb.LGBMRegressor(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.04,\n",
    "        num_leaves=48,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        random_state=SEED,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    severity_model.fit(X_tr, y_severity_tr)\n",
    "\n",
    "    severity_preds[val_idx] = severity_model.predict(X_val)\n",
    "    severity_test_preds[:, fold] = severity_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c95f75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Accuracy: 0.7639213071023675\n",
      "Secondary Accuracy: 0.6552184061353784\n",
      "Severity R2: 0.9971679477549317\n",
      "FINAL SCORE: 0.790414138911341\n"
     ]
    }
   ],
   "source": [
    "primary_acc = accuracy_score(train_df[\"primary_label\"], primary_preds)\n",
    "secondary_acc = accuracy_score(train_df[\"secondary_label\"], secondary_preds)\n",
    "severity_r2 = r2_score(severity, severity_preds)\n",
    "\n",
    "final_score = (\n",
    "    PRIMARY_WEIGHT * primary_acc +\n",
    "    SECONDARY_WEIGHT * secondary_acc +\n",
    "    SEVERITY_WEIGHT * severity_r2\n",
    ")\n",
    "\n",
    "print(\"Primary Accuracy:\", primary_acc)\n",
    "print(\"Secondary Accuracy:\", secondary_acc)\n",
    "print(\"Severity R2:\", severity_r2)\n",
    "print(\"FINAL SCORE:\", final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5340bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_test_final = np.round(primary_test_preds.mean(axis=1)).astype(int)\n",
    "\n",
    "# ----- SECONDARY PROBABILITY BOOST -----\n",
    "\n",
    "# Weighted fold averaging\n",
    "weights = np.array([0.15, 0.2, 0.2, 0.22, 0.23])\n",
    "\n",
    "secondary_test_final = np.tensordot(\n",
    "    secondary_test_preds,\n",
    "    weights,\n",
    "    axes=(2, 0)\n",
    ")\n",
    "\n",
    "# Temperature smoothing\n",
    "secondary_test_final = np.power(secondary_test_final, 1.1)\n",
    "\n",
    "# Re-normalize probabilities\n",
    "secondary_test_final = secondary_test_final / secondary_test_final.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "# ----- SEVERITY -----\n",
    "severity_test_final = severity_test_preds.mean(axis=1)\n",
    "severity_test_final = np.clip(severity_test_final, 1, 5)\n",
    "severity_test_final = np.floor(severity_test_final + 0.55).astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c35dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_labels = primary_le.inverse_transform(primary_test_final)\n",
    "secondary_labels = secondary_le.inverse_transform(\n",
    "    np.argmax(secondary_test_final, axis=1)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c727d1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>secondary_category</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7799230</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15754196</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Written notification about debt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10989146</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "      <td>Problem with a company's investigation into an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3617850</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5253879</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complaint_id                                   primary_category  \\\n",
       "0       7799230  Credit reporting or other personal consumer re...   \n",
       "1      15754196                                    Debt collection   \n",
       "2      10989146  Credit reporting or other personal consumer re...   \n",
       "3       3617850  Credit reporting, credit repair services, or o...   \n",
       "4       5253879  Credit reporting or other personal consumer re...   \n",
       "\n",
       "                                  secondary_category  severity  \n",
       "0               Incorrect information on your report         1  \n",
       "1                    Written notification about debt         1  \n",
       "2  Problem with a company's investigation into an...         2  \n",
       "3  Problem with a credit reporting company's inve...         1  \n",
       "4                        Improper use of your report         4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"complaint_id\": test_df[\"complaint_id\"],\n",
    "    \"primary_category\": primary_labels,\n",
    "    \"secondary_category\": secondary_labels,\n",
    "    \"severity\": severity_test_final\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
